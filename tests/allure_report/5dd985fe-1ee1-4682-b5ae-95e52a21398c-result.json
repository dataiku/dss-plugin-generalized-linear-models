{"name": "test_link_function", "status": "broken", "statusDetails": {"message": "statsmodels.tools.sm_exceptions.PerfectSeparationError: Perfect separation detected, results not available", "trace": "def test_link_function():\n        case = unittest.TestCase()\n        expected = [\n            sm.families.links.log(),\n            sm.families.links.identity(),\n            sm.families.links.inverse_power(),\n            sm.families.links.inverse_squared(),\n            sm.families.links.log(),\n            sm.families.links.cloglog(),\n            sm.families.links.Power(1),\n        ]\n    \n        actual = []\n    \n        X = np.random.rand(1000, 1000)\n        y = pd.Series(np.random.randint(2, size=1000))\n    \n        for test in testing_dict:\n            test_params = testing_dict[test]\n            binary_model = BinaryClassificationGLM(\n                family_name=test_params['family_name'],\n                binomial_link=test_params['binomial_link'],\n                gamma_link=test_params['gamma_link'],\n                gaussian_link=test_params['gaussian_link'],\n                inverse_gaussian_link=test_params['inverse_gaussian_link'],\n                poisson_link=test_params['poisson_link'],\n                negative_binomial_link=test_params['negative_binomial_link'],\n                tweedie_link=test_params['tweedie_link'],\n                alpha=1,\n                power=1,\n                var_power=1\n            )\n>           binary_model.fit_model(X, y)\n\ntests/python/unit/test_binary_model.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \npython-lib/generalized_linear_models/dku_glm.py:121: in fit_model\n    self.fitted_model = model.fit()\n../../virtual_environments/glm_testing/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py:1063: in fit\n    return self._fit_irls(start_params=start_params, maxiter=maxiter,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <statsmodels.genmod.generalized_linear_model.GLM object at 0x12bfd9970>, start_params = array([0., 0., 0., ..., 0., 0., 0.]), maxiter = 100, tol = 1e-08, scale = None, cov_type = 'nonrobust'\ncov_kwds = None, use_t = None, kwargs = {}, attach_wls = False, atol = 1e-08, rtol = 0.0, tol_criterion = 'deviance', wls_method = 'lstsq'\nendog = array([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,...0, 0, 0,\n       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 1, 1, 0, 1, 1])\nwlsexog = array([[1.        , 0.92591711, 0.07151993, ..., 0.60514966, 0.68790218,\n        0.03336248],\n       [1.        , 0.51...84,\n        0.95205831],\n       [1.        , 0.61603868, 0.59713634, ..., 0.03797828, 0.37427859,\n        0.67419712]])\n\n    def _fit_irls(self, start_params=None, maxiter=100, tol=1e-8,\n                  scale=None, cov_type='nonrobust', cov_kwds=None,\n                  use_t=None, **kwargs):\n        \"\"\"\n        Fits a generalized linear model for a given family using\n        iteratively reweighted least squares (IRLS).\n        \"\"\"\n        attach_wls = kwargs.pop('attach_wls', False)\n        atol = kwargs.get('atol')\n        rtol = kwargs.get('rtol', 0.)\n        tol_criterion = kwargs.get('tol_criterion', 'deviance')\n        wls_method = kwargs.get('wls_method', 'lstsq')\n        atol = tol if atol is None else atol\n    \n        endog = self.endog\n        wlsexog = self.exog\n        if start_params is None:\n            start_params = np.zeros(self.exog.shape[1])\n            mu = self.family.starting_mu(self.endog)\n            lin_pred = self.family.predict(mu)\n        else:\n            lin_pred = np.dot(wlsexog, start_params) + self._offset_exposure\n            mu = self.family.fitted(lin_pred)\n        self.scale = self.estimate_scale(mu)\n        dev = self.family.deviance(self.endog, mu, self.var_weights,\n                                   self.freq_weights, self.scale)\n        if np.isnan(dev):\n            raise ValueError(\"The first guess on the deviance function \"\n                             \"returned a nan.  This could be a boundary \"\n                             \" problem and should be reported.\")\n    \n        # first guess on the deviance is assumed to be scaled by 1.\n        # params are none to start, so they line up with the deviance\n        history = dict(params=[np.inf, start_params], deviance=[np.inf, dev])\n        converged = False\n        criterion = history[tol_criterion]\n        # This special case is used to get the likelihood for a specific\n        # params vector.\n        if maxiter == 0:\n            mu = self.family.fitted(lin_pred)\n            self.scale = self.estimate_scale(mu)\n            wls_results = lm.RegressionResults(self, start_params, None)\n            iteration = 0\n        for iteration in range(maxiter):\n            self.weights = (self.iweights * self.n_trials *\n                            self.family.weights(mu))\n            wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n                        - self._offset_exposure)\n            wls_mod = reg_tools._MinimalWLS(wlsendog, wlsexog,\n                                            self.weights, check_endog=True,\n                                            check_weights=True)\n            wls_results = wls_mod.fit(method=wls_method)\n            lin_pred = np.dot(self.exog, wls_results.params)\n            lin_pred += self._offset_exposure\n            mu = self.family.fitted(lin_pred)\n            history = self._update_history(wls_results, mu, history)\n            self.scale = self.estimate_scale(mu)\n            if endog.squeeze().ndim == 1 and np.allclose(mu - endog, 0):\n                msg = \"Perfect separation detected, results not available\"\n>               raise PerfectSeparationError(msg)\nE               statsmodels.tools.sm_exceptions.PerfectSeparationError: Perfect separation detected, results not available\n\n../../virtual_environments/glm_testing/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py:1211: PerfectSeparationError"}, "start": 1626698209236, "stop": 1626698212625, "uuid": "0111887a-8592-40b0-91d1-dc01fc163c03", "historyId": "0ee3139cccf812ac482ec371576bf025", "testCaseId": "75263fef66c1493db6559bdc12d54d2e", "fullName": "tests.python.unit.test_binary_model#test_link_function", "labels": [{"name": "parentSuite", "value": "tests.python.unit"}, {"name": "suite", "value": "test_binary_model"}, {"name": "host", "value": "Matthews-MBP"}, {"name": "thread", "value": "16414-MainThread"}, {"name": "framework", "value": "pytest"}, {"name": "language", "value": "cpython3"}, {"name": "package", "value": "tests.python.unit.test_binary_model"}]}